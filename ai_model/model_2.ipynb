{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1e9950bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /Users/paabonsu/Documents/Personal/AI/sneaker-ai/.venv/lib/python3.13/site-packages (4.67.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tqdm\n",
    "import os\n",
    "import time\n",
    "import torch.nn as nn\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9af3e0fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Using Apple Metal (MPS)\n"
     ]
    }
   ],
   "source": [
    "# Check GPU / MPS (for Mac)\n",
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"✅ Using GPU (CUDA)\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"✅ Using Apple Metal (MPS)\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"⚠️ Using CPU — training will be slower\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1aed3417",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Dataset (for JPEG-bytes in Parquet)\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class SneakerDataset(Dataset):\n",
    "    def __init__(self, df, label_col=\"brand\", transform=None):\n",
    "        self.df = df\n",
    "        self.images = df['image'].values\n",
    "        self.labels = df[label_col].astype('category').cat.codes\n",
    "        self.label2name = dict(enumerate(df[label_col].astype('category').cat.categories))\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_bytes = self.images[idx]\n",
    "        if isinstance(img_bytes, str):\n",
    "            img_bytes = bytes(img_bytes, 'utf-8')\n",
    "        image = Image.open(io.BytesIO(img_bytes)).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        label = torch.tensor(self.labels.iloc[idx], dtype=torch.long)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "16f3b7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Transforms (resize + augment)\n",
    "from torchvision import models, transforms\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "transform_val = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "05ae8ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Combined Dataset\n",
    "import pandas as pd\n",
    "\n",
    "# Load precombined dataset\n",
    "df = pd.read_parquet(\"all_sneakers_combined.parquet\")\n",
    "\n",
    "# Drop incomplete rows\n",
    "df = df.dropna(subset=['image', 'brand'])\n",
    "df = df.groupby('brand').filter(lambda x: len(x) > 5)\n",
    "\n",
    "# Encode once for stratified split\n",
    "df['brand'] = df['brand'].astype('category')\n",
    "df['label'] = df['brand'].cat.codes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "24234b7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 72864, Validation: 18217\n"
     ]
    }
   ],
   "source": [
    "# Balanced Train/Val Split\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, val_df = train_test_split(\n",
    "    df, test_size=0.2, stratify=df['label'], random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Train samples: {len(train_df)}, Validation: {len(val_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9708661c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'Adidas', 1: 'Alexander', 2: 'Amiri', 3: 'Asics', 4: 'Autry', 5: 'BAPE', 6: 'Balenciaga', 7: 'Birkenstock', 8: 'Camper', 9: 'Clarks', 10: 'Converse', 11: 'Crocs', 12: 'Diadora', 13: 'Dr.', 14: 'Ewing', 15: 'Hoka', 16: 'Jordan', 17: 'KangaROOS', 18: 'Karhu', 19: 'Keen', 20: 'Lacoste', 21: 'Lanvin', 22: 'Le', 23: 'Mizuno', 24: 'Moon', 25: 'New', 26: 'Nike', 27: 'ON', 28: 'Off-White', 29: 'Onitsuka', 30: 'Puma', 31: 'Reebok', 32: 'Salomon', 33: 'Saucony', 34: 'Suicoke', 35: 'Timberland', 36: 'Vans', 37: 'Veja', 38: 'adidas', 39: 'alexander'}\n"
     ]
    }
   ],
   "source": [
    "# DataLoaders\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataset = SneakerDataset(train_df, transform=transform_train)\n",
    "val_dataset = SneakerDataset(val_df, transform=transform_val)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=64, shuffle=True,\n",
    "    num_workers=0, pin_memory=True\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, batch_size=64, shuffle=False,\n",
    "    num_workers=0, pin_memory=True\n",
    ")\n",
    "print(train_dataset.label2name )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c37f781f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded ResNet18 weights from local file successfully.\n"
     ]
    }
   ],
   "source": [
    "# Model, Loss, Optimizer, Scaler\n",
    "from torchvision import models\n",
    "\n",
    "num_classes = len(set(train_dataset.labels))\n",
    "\n",
    "# path to the downloaded weights\n",
    "weights_path = os.path.expanduser(\"~/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\")\n",
    "\n",
    "# load model without triggering an online download\n",
    "model = models.resnet18(weights=None)\n",
    "state_dict = torch.load(weights_path, map_location=\"cpu\")\n",
    "model.load_state_dict(state_dict)\n",
    "\n",
    "print(\"✅ Loaded ResNet18 weights from local file successfully.\")\n",
    "\n",
    "\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "scaler = torch.amp.GradScaler('cuda') if torch.cuda.is_available() else torch.amp.GradScaler('cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "881085c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/15] Training:   0%|          | 0/1139 [00:00<?, ?it/s]/Users/paabonsu/Documents/Personal/AI/sneaker-ai/.venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📉 Epoch [1] Avg Loss: 0.7836\n",
      "🎯 Validation Accuracy: 85.06%\n",
      "💾 New best model saved (Acc: 85.06%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📉 Epoch [2] Avg Loss: 0.3726\n",
      "🎯 Validation Accuracy: 89.19%\n",
      "💾 New best model saved (Acc: 89.19%)\n",
      "📍 Saved checkpoint at epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📉 Epoch [3] Avg Loss: 0.2606\n",
      "🎯 Validation Accuracy: 89.71%\n",
      "💾 New best model saved (Acc: 89.71%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📉 Epoch [4] Avg Loss: 0.2039\n",
      "🎯 Validation Accuracy: 91.15%\n",
      "💾 New best model saved (Acc: 91.15%)\n",
      "📍 Saved checkpoint at epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📉 Epoch [5] Avg Loss: 0.1594\n",
      "🎯 Validation Accuracy: 91.13%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📉 Epoch [6] Avg Loss: 0.1381\n",
      "🎯 Validation Accuracy: 91.08%\n",
      "📍 Saved checkpoint at epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📉 Epoch [7] Avg Loss: 0.1193\n",
      "🎯 Validation Accuracy: 91.65%\n",
      "💾 New best model saved (Acc: 91.65%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📉 Epoch [8] Avg Loss: 0.1046\n",
      "🎯 Validation Accuracy: 91.79%\n",
      "💾 New best model saved (Acc: 91.79%)\n",
      "📍 Saved checkpoint at epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📉 Epoch [9] Avg Loss: 0.0952\n",
      "🎯 Validation Accuracy: 92.14%\n",
      "💾 New best model saved (Acc: 92.14%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📉 Epoch [10] Avg Loss: 0.0876\n",
      "🎯 Validation Accuracy: 92.01%\n",
      "📍 Saved checkpoint at epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📉 Epoch [11] Avg Loss: 0.0803\n",
      "🎯 Validation Accuracy: 92.33%\n",
      "💾 New best model saved (Acc: 92.33%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📉 Epoch [12] Avg Loss: 0.0781\n",
      "🎯 Validation Accuracy: 92.02%\n",
      "📍 Saved checkpoint at epoch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📉 Epoch [13] Avg Loss: 0.0704\n",
      "🎯 Validation Accuracy: 91.38%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📉 Epoch [14] Avg Loss: 0.0681\n",
      "🎯 Validation Accuracy: 92.47%\n",
      "💾 New best model saved (Acc: 92.47%)\n",
      "📍 Saved checkpoint at epoch 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📉 Epoch [15] Avg Loss: 0.0663\n",
      "🎯 Validation Accuracy: 92.30%\n"
     ]
    }
   ],
   "source": [
    "# Training Loop (optimized)\n",
    "from tqdm import tqdm\n",
    "\n",
    "EPOCHS = 15\n",
    "best_acc = 0.0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    loop = tqdm(train_loader, desc=f\"Epoch [{epoch+1}/{EPOCHS}] Training\", leave=False)\n",
    "    for imgs, labels in loop:\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        with  torch.amp.autocast(device_type=device.type):\n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, labels)\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "\n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "    print(f\"📉 Epoch [{epoch+1}] Avg Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    # --- Validation ---\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in val_loader:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            outputs = model(imgs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (preds == labels).sum().item()\n",
    "\n",
    "    val_acc = 100 * correct / total\n",
    "    print(f\"🎯 Validation Accuracy: {val_acc:.2f}%\")\n",
    "\n",
    "    # --- Save best model ---\n",
    "    if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "        torch.save(model.state_dict(), \"best_sneaker_model.pth\")\n",
    "        print(f\"💾 New best model saved (Acc: {best_acc:.2f}%)\")\n",
    "\n",
    "    # --- Save checkpoint every 2 epochs ---\n",
    "    if (epoch + 1) % 2 == 0:\n",
    "        torch.save(model.state_dict(), f\"checkpoint_epoch_{epoch+1}.pth\")\n",
    "        print(f\"📍 Saved checkpoint at epoch {epoch+1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7f9288e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: Asics | Actual: Asics\n"
     ]
    }
   ],
   "source": [
    "# Quick Prediction Test\n",
    "\n",
    "model.eval()\n",
    "img_tensor, label = val_dataset[0]\n",
    "img_tensor = img_tensor.unsqueeze(0).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(img_tensor)\n",
    "    _, pred = torch.max(outputs, 1)\n",
    "\n",
    "predicted_label = train_dataset.label2name[pred.item()]\n",
    "actual_label = train_dataset.label2name[label.item()]\n",
    "\n",
    "print(f\"Predicted: {predicted_label} | Actual: {actual_label}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
